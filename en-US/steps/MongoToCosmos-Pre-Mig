<!--Pre-migration overview-->

As you prepare for migrating to the cloud, verify that you are migrating from a MongoDB source with version 3.4  or earlier.

Please do not hesitate to reach out to [askcosmosdb@microsoft.com](mailto:askcosmosdb@microsoft.com) with questions.

### Additional resources

For a matrix of the Microsoft and third-party services and tools that are available to assist you with various database and data migration scenarios as well as specialty tasks, see the article [Service and tools for data migration](https://docs.microsoft.com/azure/dms/dms-tools-matrix).

### Preparation of target Cosmos DB account

1. You must create relevant Cosmos DB resources before migrating any data. Create an Azure Cosmos DB account and select MongoDB as the API. Pre-create your databases through the Azure portal. 

    ![Create a Cosmos DB account](https://mpbdevcontent.azureedge.net/Images/mongo-create-cosmos-account.png)


#### Request Units can be provisioned at two granularities 
 

**Collection-level throughput:** 

- Can be set for fixed collections or unlimited collections (with partitions) 
 

    *When is this best?* 

    - If there are a small number of Azure Cosmos DB containers 
    - If you want to get the guaranteed throughput on a given container backed by SLA 

**Database-level throughput:** 

- If throughput for the entire database will be over 10,000 RU’s, it can be shared among any unlimited collections within the database. This can provide significant savings.
- If MongoDB collections were sharded, they can migrate to unlimited collections on Cosmos DB and be eligible for database-level throughput. If MongoDB collections are not sharded, it is easy to specify a partition key during the migration 

    *When is this best?* 

    - If you want to consider unplanned spikes in workloads by using pooled throughput at the database level 

2. For customers that are migrating many collections within a database, it is strongly recommend to configure database-level throughput. You must make this choice when you create the database. The minimum database-level [throughput capacity](https://docs.microsoft.com/azure/cosmos-db/request-units) is 10,000 RU’s.

    ![Create a Cosmos DB database](https://mpbdevcontent.azureedge.net/Images/mongo-create-db.png)

3. Pre-create your collections through the Azure portal. It is strongly recommended that you create unlimited collections and specify a [shard key](https://docs.microsoft.com/en-us/azure/cosmos-db/partition-data). Setting the partition key/shard key, if applicable, must be done **prior** to the migration.

    ![Create a Cosmos DB collection](https://mpbdevcontent.azureedge.net/Images/mongo-create-collection.png)

    Alternatively, you could create a fixed collection. You do not need to specify a partition key for fixed collection. Fixed collections have a 10GB max size.

    Collections can share the [throughput (RU/sec)](https://docs.microsoft.com/azure/cosmos-db/set-throughput) of a parent database if throughput has been defined at the database-level. You can also provision a dedicated amount of throughput (independent of the parent databases) at the collection-level. If throughput is not defined at a database-level, it must be defined at the collection level. Unlimited collections require a minimum of 1,000 RU/sec, while fixed collections have a minimum of 400 RU/sec.

4. The duration of the migration will depend on the amount of throughput you set for each collection or database. For large data migrations, you should temporarily increase the throughput across your collections and databases.
