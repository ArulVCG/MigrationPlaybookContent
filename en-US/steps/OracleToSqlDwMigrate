<!--Migrate from Oracle to SQL Data Warehouse-->

The following sections provide an overview of what's involved with migrating an existing database solution to Azure SQL Data Warehouse.

### Profile your workload

Before migrating, you should verify that SQL Data Warehouse is the best solution for your workload. SQL Data Warehouse is a distributed system designed to perform analytics on large data. Migrating to SQL Data Warehouse requires some design changes that are not difficult to understand but that might take some time to implement. If your business requires an enterprise-class data warehouse, the benefits are worth the effort. However, if you don't need the power of SQL Data Warehouse, it is more cost-effective to use [SQL Server]( https://docs.microsoft.com/en-us/sql/sql-server/sql-server-technical-documentation?view=sql-server-2017) or [Azure SQL Database](https://azure.microsoft.com/services/sql-database/).

Consider using SQL Data Warehouse when you:
* Have one or more Terabytes of data
* Plan to run analytics on substantial amounts of data
* Need the ability to scale compute and storage
* Want to save on costs by pausing compute resources when you don't need them.

Rather than SQL Data Warehouse, consider other options for operational (OLTP) workloads that have:
* High frequency reads and writes
* Large numbers of singleton selects
* High volumes of single row inserts
* Row-by-row processing needs
* Incompatible formats (JSON, XML)

### Plan the migration

After you make the decision to migrate an existing solution to SQL Data Warehouse, it is important to plan the migration before you get started.
A primary goal of planning is to ensure that your data, table schemas, and code are compatible with SQL Data Warehouse. There are some compatibility differences between your current system and SQL Data Warehouse that you will need to work around. In addition, migrating large amounts of data to Azure takes time. Careful planning will speed up the process of getting your data to Azure.
Another key goal of planning is to adjust your design to ensure that your solution takes full advantage of the high query performance that SQL Data Warehouse is designed to provide. Designing data warehouses for scale introduces unique design patterns, so traditional approaches aren't always the best. While some design adjustments can be made after migration, making changes earlier in the process will save you time later.

### Perform the migration

Performing a successful migration required you to migrate your table schemas, code, and data. For more detailed guidance on these topics, see:
* The article [Migrate your schemas](https://docs.microsoft.com/en-us/azure/sql-data-warehouse/sql-data-warehouse-migrate-schema).
* The article [Migrate your code](https://docs.microsoft.com/en-us/azure/sql-data-warehouse/sql-data-warehouse-migrate-schema).
* The article [Migrate your data](https://docs.microsoft.com/en-us/azure/sql-data-warehouse/sql-data-warehouse-migrate-data).

### Additional resources

- The CAT (Customer Advisory Team) also has some great SQL Data Warehouse guidance, which they publish through blogs. Be sure to take a look at their blog posting, [Migrating data to Azure SQL Data Warehouse in practice](https://blogs.msdn.microsoft.com/sqlcat/2016/08/18/migrating-data-to-azure-sql-data-warehouse-in-practice/), for additional guidance on migration.
- For a matrix of the Microsoft and third-party services and tools that are available to assist you with various database and data migration scenarios as well as specialty tasks, see the article [Service and tools for data migration](https://docs.microsoft.com/azure/dms/dms-tools-matrix).

### Migration learnings and best practices from real-world engagements

For additional assistance with completing this migration scenario, please see the following resources, which were developed in support of a real-world migration project engagement.

<br>
<table width="100%">
<thead>
<tr>
<td width="18%">
<p><strong>Title/link</strong></p>
</td>
<td width="59%">
<p><strong>Description</strong></p>
</td>
</tr>
</thead>
<tbody>
<tr>
<td width="18%">
<p><a href="https://github.com/Microsoft/DataMigrationTeam/tree/master/Data%20Workload%20Assessment%20Model%20and%20Tool">Data Workload Assessment Model and Tool</a></p>
</td>
<td width="59%">
<p>This tool provides suggested &ldquo;best fit&rdquo; target platforms, cloud readiness, and application/database remediation level for a given workload. It offers simple, one-click calculation and report generation that greatly helps to accelerate large estate assessments by providing and automated and uniform target platform decision process.</p>
</td>
</tr>
<tr>
<td width="18%">
<p><a href="https://github.com/Microsoft/DataMigrationTeam/tree/master/Oracle%20Inventory%20Script%20Artifacts">Oracle Inventory Script Artifacts</a></p>
</td>
<td width="59%">
<p>This asset includes a PL/SQL query that hits Oracle system tables and provides a count of objects by schema type, object type, and status. It also provides a rough estimate of &lsquo;Raw Data&rsquo; in each schema and the sizing of tables in each schema, with results stored in a CSV format.</p>
</td>
</tr>
<tr>
<td width="18%">
<p><a href="https://github.com/Microsoft/DataMigrationTeam/tree/master/SSMA%20Assessment%20Tool">SSMA Assessment Tool</a></p>
</td>
<td width="59%">
<p>This set of resource uses a .csv file as entry (sources.csv in the project folders) to produce the xml files that are needed to run SSMA assessment in console mode. The source.csv is provided by the customer based on an inventory of existing Oracle instances. The output files are <strong>AssessmentReportGeneration_source_1.xml</strong>, <strong>ServersConnectionFile.xml</strong>, and <strong>VariableValueFile.xml</strong>.</p>
</td>
</tr>
<tr>
<td width="18%">
<p><a href="http://download.microsoft.com/download/9/0/7/9076AB70-431D-4F2B-A70E-2837BEBD0BE8/Bug%20Free%20Polybase%20Load%20Method.docx">Bug Free Polybase Load Method</a></p>
</td>
<td width="59%">
<p>This guide covers an approach for a bug free Polybase Load using Azure Data Factory (ADF). The following caveats apply:</p>
<ul>
<li>You need to guarantee the files being extracted are UTF-8/UTF-16 compatible (you can follow this white paper to achieve this)</li>
<li>You need to guarantee NULL values are handled correctly &ndash; use empty string</li>
</ul>
</td>
</tr>
<tr>
<td width="18%">
<p><a href="http://download.microsoft.com/download/5/0/2/502B793F-4079-40C8-A2B7-6F7BC7167784/Getting%20table%20sizes%20in%20SQL%20DW.docx">Getting table sizes in SQL DW</a></p>
</td>
<td width="59%">
<p>One of the key tasks that an architect must perform execute is to get metrics about a new environment post-migration: collecting load times from on-premises to the cloud, collecting Polybase load times, etc. Of these tasks, one of the most important is to determine the storage size in SQL Data Warehouse compared to the customer's current platform.</p>
</td>
</tr>
<tr>
<td width="18%">
<p><a href="http://download.microsoft.com/download/A/1/E/A1E377CF-5D4A-4F70-9210-8F98F7BB9E11/Netezza%20to%20SQL%20DW%20Recommended%20Datatype%20Mapping.docx">Netezza to SQL DW Recommended Datatype Mapping</a></p>
</td>
<td width="59%">
<p>This white paper describes recommended data type mapping between Netezza and Azure SQL Data Warehouse.</p>
</td>
</tr>
<tr>
<td width="18%">
<p><a href="https://azure.microsoft.com/en-us/blog/handling-data-encoding-issues-while-loading-data-to-sql-data-warehouse/">Handling Data Encoding Issues While Loading Data to SQL Data Warehouse</a></p>
</td>
<td width="59%">
<p>This blog is intended to provide insight on some of the data encoding issues that you may encounter while using Polybase to load data to SQL Data Warehouse. This article also provides some options that you can use to overcome such issues and load the data successfully.</p>
</td>
</tr>
<tr>
<td width="18%">
<p><a href="http://download.microsoft.com/download/7/A/4/7A461726-2669-4CBD-BD8F-30635A137D89/Azure%20VM%20-%20Oracle%2012c%20on%20Linux%20-%20Configuration%20Steps%20-%20working.docx">Setting up Oracle 12c Enterprise and Getting It Working by Using the Azure Marketplace Template</a></p>
</td>
<td width="59%">
<p>This white paper provides a step-by-step walkthrough of setting up and implementing Oracle 12c Enterprise by using the Azure Marketplace Template.</p>
</td>
</tr>
</tbody>
</table>

**Note**: These resources were developed as part of the Data Migration Jumpstart Program (DM Jumpstart), which is sponsored by the Azure Data Group engineering team. The core charter DM Jumpstart is to unblock and accelerate complex modernization and compete data platform migration opportunities to Microsoftâ€™s Azure Data platform. If you think your organization would be interested in participating in the DM Jumpstart program, please contact your account team and ask that they submit a nomination.
